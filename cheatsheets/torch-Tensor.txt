http://pytorch.org/docs

Default numeric type in PyTorch is 32-bit floating-point.
Default numeric type in NumPy is 64-bit 

stride: 
    a tuple indicating the number of elements in the storage that have to be skipped when the index is increased by 1 in each dimension. 
Contiguous 
    a tensor whose values are laid out in the storage - 
        starting from the rightmost dimension onward


# ----------------
# Storage
# ----------------

The storage holds the elements in the tensor sequentially, row by row. 


Values in tensors are allocsted in contiguous chunks of memory managed by `torch.Storage` instances.
    One dimensional array of numerical data. 
    A contiguous block of memory containing numbers of a gviven type. 

A pytorch tensor instance is a view of such a storage instance that is capable of indexing into that storage using an offset and per-dimension strides. 

# --------------------
# In-place operations 
# --------------------

Indicated by a trailing underscore in the name. 
tensor.zero_()                                            # returns a tensor of zero's 


# ----------------
# Dtypes
# ----------------

torch.float32 or torch.float: 32-bit floating-point

torch.float64 or torch.double: 64-bit, double-precision floating-point

torch.float16 or torch.half: 16-bit, half-precision floating-point

torch.int8: signed 8-bit integers

torch.uint8: unsigned 8-bit integers

torch.int16 or torch.short: signed 16-bit integers

torch.int32 or torch.int: signed 32-bit integers

torch.int64 or torch.long: signed 64-bit integers

torch.bool: Boolean

When mixing input types in operations, the inputs are converted to the larger type automatically. 

torch.zeros(10, 2).double()                  Cast the output of a tensor creation function to the right type using the corresponding casting method. 
torch.zeros(10, 2).short()
torch.zeros(10, 2).to(torch.double)          Checks whether the conversion is necessary and if so, does it. 
torch.ones(10, 2).to(dtype=torch.short)


# ----------------------------------------
# Indexing, Slicing, Joining, Mutating Ops 
# ----------------------------------------

Transposing: 
    Changing the order of the elements in the stride. 
    No new memory is allocated 

torch.transpose(tensor, dim1, dim2)          Transpose the tensor given the dimensions (dim1, dim2) to swap
t.transpose(dim1, dim2)            
t.t()                                        Shorthand function to transpose for 2D tensors 
t.clone()                                    Clone into a new tensor. 


# ----------------
# Creation Ops 
# ----------------

torch.ones()
torch.from_numpy()
tensor_.numpy()                                # convert a tensor to a numpy array 


When using tensor_.numpy(), torch.from_numpy(np.array): 

    A NumPy multidimensional array of the right size, shape, and dtype will be returned. 
    The returned array shares the same underlying buffer with the tensor storage. 
        (This method can be executed at basically no cost) 
    Modifying the NumPy array will lead to a change in the originating tensor. 
    If the tensor is allocated on the GPU, 
        PyTorch will make a copy of the content of the tensor into a NumPy array allocated on the CPU 
    
    When changing, Numpy defaults to 64-bit, so make sure when you go back to tensor, you have dtype of torch.float (32-bit) 


# ----------------
# Random Sampling
# ----------------

# ----------------
# Parallellism
# ----------------

torch.tensor([[... , ...], [... , ...]], device = 'cuda')       # assign to GPU on creation 
torch.tensor([[... , ...], [... , ...]], device = 'cuda:0')     # (multiple gpu machine) assign to GPU 0 on creation 

tensor_.to(device='cuda')                                             # Assign existing object 
tensor_ = tensor_.cuda()                                        # assign to cuda device, default 0
tensor_ = tensor_.cpu()                                         # assign to CPU device

